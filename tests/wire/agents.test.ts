/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool";
import { CartesiaClient } from "../../src/Client";

describe("Agents", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            summaries: [
                {
                    id: "agent_123",
                    name: "cartesia-basic-chat",
                    description: "A basic chat agent",
                    created_at: "2025-08-13T12:00:00Z",
                    updated_at: "2025-08-13T12:00:00Z",
                    tts_voice: "bf0a246a-8642-498a-9950-80c35e9276b5",
                    tts_language: "en",
                    has_text_to_agent_run: false,
                    deployment_count: 1,
                    git_repository: { provider: "github", account: "cartesia-ai", name: "cartesia-basic-chat" },
                    git_deploy_branch: "main",
                    phone_numbers: [{ id: "123456", number: "+11234567890" }],
                },
                {
                    id: "agent_456",
                    name: "cartesia-outbound-calls",
                    description: "An agent that makes outbound calls",
                    created_at: "2025-08-13T12:00:00Z",
                    updated_at: "2025-08-13T12:00:00Z",
                    tts_voice: "78ab82d5-25be-4f7d-82b3-7ad64e5b85b2",
                    tts_language: "en",
                    has_text_to_agent_run: false,
                    deployment_count: 1,
                    git_repository: { provider: "github", account: "cartesia-ai", name: "cartesia-outbound-calls" },
                    git_deploy_branch: "main",
                    phone_numbers: [{ id: "789012", number: "+11234567890" }],
                },
            ],
        };
        server.mockEndpoint().get("/agents/").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.agents.list();
        expect(response).toEqual({
            summaries: [
                {
                    id: "agent_123",
                    name: "cartesia-basic-chat",
                    description: "A basic chat agent",
                    createdAt: new Date("2025-08-13T12:00:00.000Z"),
                    updatedAt: new Date("2025-08-13T12:00:00.000Z"),
                    ttsVoice: "bf0a246a-8642-498a-9950-80c35e9276b5",
                    ttsLanguage: "en",
                    hasTextToAgentRun: false,
                    deploymentCount: 1,
                    gitRepository: {
                        provider: "github",
                        account: "cartesia-ai",
                        name: "cartesia-basic-chat",
                    },
                    gitDeployBranch: "main",
                    phoneNumbers: [
                        {
                            id: "123456",
                            number: "+11234567890",
                        },
                    ],
                },
                {
                    id: "agent_456",
                    name: "cartesia-outbound-calls",
                    description: "An agent that makes outbound calls",
                    createdAt: new Date("2025-08-13T12:00:00.000Z"),
                    updatedAt: new Date("2025-08-13T12:00:00.000Z"),
                    ttsVoice: "78ab82d5-25be-4f7d-82b3-7ad64e5b85b2",
                    ttsLanguage: "en",
                    hasTextToAgentRun: false,
                    deploymentCount: 1,
                    gitRepository: {
                        provider: "github",
                        account: "cartesia-ai",
                        name: "cartesia-outbound-calls",
                    },
                    gitDeployBranch: "main",
                    phoneNumbers: [
                        {
                            id: "789012",
                            number: "+11234567890",
                        },
                    ],
                },
            ],
        });
    });

    test("get", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "agent_123",
            name: "cartesia-basic-chat",
            created_at: "2025-08-13T12:00:00Z",
            updated_at: "2025-08-13T12:00:00Z",
            tts_voice: "bf0a246a-8642-498a-9950-80c35e9276b5",
            tts_language: "en",
            has_text_to_agent_run: false,
            deployment_count: 1,
            git_repository: { provider: "github", account: "cartesia-ai", name: "cartesia-basic-chat" },
            git_deploy_branch: "main",
            phone_numbers: [{ id: "123456", number: "+11234567890" }],
        };
        server.mockEndpoint().get("/agents/agent_123").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.agents.get("agent_123");
        expect(response).toEqual({
            id: "agent_123",
            name: "cartesia-basic-chat",
            createdAt: new Date("2025-08-13T12:00:00.000Z"),
            updatedAt: new Date("2025-08-13T12:00:00.000Z"),
            ttsVoice: "bf0a246a-8642-498a-9950-80c35e9276b5",
            ttsLanguage: "en",
            hasTextToAgentRun: false,
            deploymentCount: 1,
            gitRepository: {
                provider: "github",
                account: "cartesia-ai",
                name: "cartesia-basic-chat",
            },
            gitDeployBranch: "main",
            phoneNumbers: [
                {
                    id: "123456",
                    number: "+11234567890",
                },
            ],
        });
    });

    test("update", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });
        const rawRequestBody = { tts_voice: "bf0a246a-8642-498a-9950-80c35e9276b5", tts_language: "en" };
        const rawResponseBody = {
            id: "agent_123",
            name: "cartesia-basic-chat-updated",
            created_at: "2025-08-13T12:00:00Z",
            updated_at: "2025-08-13T12:00:00Z",
            tts_voice: "bf0a246a-8642-498a-9950-80c35e9276b5",
            tts_language: "en",
            has_text_to_agent_run: false,
            deployment_count: 1,
            phone_numbers: [{ id: "123456", number: "+11234567890" }],
        };
        server
            .mockEndpoint()
            .patch("/agents/agent_123")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.update("agent_123", {
            ttsVoice: "bf0a246a-8642-498a-9950-80c35e9276b5",
            ttsLanguage: "en",
        });
        expect(response).toEqual({
            id: "agent_123",
            name: "cartesia-basic-chat-updated",
            createdAt: new Date("2025-08-13T12:00:00.000Z"),
            updatedAt: new Date("2025-08-13T12:00:00.000Z"),
            ttsVoice: "bf0a246a-8642-498a-9950-80c35e9276b5",
            ttsLanguage: "en",
            hasTextToAgentRun: false,
            deploymentCount: 1,
            phoneNumbers: [
                {
                    id: "123456",
                    number: "+11234567890",
                },
            ],
        });
    });

    test("delete", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        server.mockEndpoint().delete("/agents/agent_id").respondWith().statusCode(200).build();

        const response = await client.agents.delete("agent_id");
        expect(response).toEqual(undefined);
    });

    test("templates", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            templates: [
                {
                    id: "cartesia-basic-chat",
                    name: "Cartesia Basic Chat",
                    description: "A basic chat agent",
                    owner_id: "cartesia-ai",
                    repo_url: "https://github.com/cartesia-ai/straw",
                    root_dir: "",
                    created_at: "2025-07-25T06:50:12.889Z",
                    updated_at: "2025-07-25T06:50:12.889Z",
                    required_env_vars: undefined,
                    dependencies: undefined,
                },
            ],
        };
        server.mockEndpoint().get("/agents/templates").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.agents.templates();
        expect(response).toEqual({
            templates: [
                {
                    id: "cartesia-basic-chat",
                    name: "Cartesia Basic Chat",
                    description: "A basic chat agent",
                    ownerId: "cartesia-ai",
                    repoUrl: "https://github.com/cartesia-ai/straw",
                    rootDir: "",
                    createdAt: new Date("2025-07-25T06:50:12.889Z"),
                    updatedAt: new Date("2025-07-25T06:50:12.889Z"),
                    requiredEnvVars: undefined,
                    dependencies: undefined,
                },
            ],
        });
    });

    test("get-call", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "ac_sid_123",
            agent_id: "agent_123",
            start_time: "2025-08-13T17:43:58.698624Z",
            end_time: "2025-08-13T17:44:19.253128Z",
            transcript: [
                {
                    role: "assistant",
                    text: "Hi there!",
                    text_chunks: [
                        { text: "Hi", start_timestamp: 1.20720063 },
                        { text: "there!", start_timestamp: 1.40457024 },
                    ],
                    start_timestamp: 0,
                    end_timestamp: 1.5892063492063493,
                    end_reason: "interrupted",
                    tts_ttfb: 0.28243207931518555,
                },
                {
                    role: "user",
                    text: "-",
                    text_chunks: [{ text: "-", start_timestamp: 1.3892063492063493 }],
                    start_timestamp: 1.3892063492063493,
                    end_timestamp: 3.2721995464852607,
                    vad_buffer_ms: 820,
                },
                {
                    role: "assistant",
                    text: "I'm",
                    text_chunks: [{ text: "I'm", start_timestamp: 0.058049886 }],
                    start_timestamp: 4.581201814058957,
                    end_timestamp: 5.235691609977324,
                    end_reason: "interrupted",
                },
                {
                    role: "user",
                    text: "Hi, Savannah. Nice to meet you.",
                    text_chunks: [{ text: "Hi, Savannah. Nice to meet you.", start_timestamp: 5.035691609977324 }],
                    start_timestamp: 5.035691609977324,
                    end_timestamp: 7.058956916099773,
                    vad_buffer_ms: 464,
                },
                {
                    role: "assistant",
                    text: "It's",
                    text_chunks: [{ text: "It's", start_timestamp: 0.058049886 }],
                    start_timestamp: 8.788707482993198,
                    end_timestamp: 11.359954648526077,
                    end_reason: "call_ended",
                },
            ],
            telephony_params: { to: "+11234567890", from: "+11234567890" },
            summary:
                "A brief, fragmented greeting exchange occurs where the human says hello to someone named Savannah.",
            status: "completed",
            deployment_id: "ad_456",
        };
        server
            .mockEndpoint()
            .get("/agents/calls/ac_abc123")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.getCall("ac_abc123");
        expect(response).toEqual({
            id: "ac_sid_123",
            agentId: "agent_123",
            startTime: new Date("2025-08-13T17:43:58.698Z"),
            endTime: new Date("2025-08-13T17:44:19.253Z"),
            transcript: [
                {
                    role: "assistant",
                    text: "Hi there!",
                    textChunks: [
                        {
                            text: "Hi",
                            startTimestamp: 1.20720063,
                        },
                        {
                            text: "there!",
                            startTimestamp: 1.40457024,
                        },
                    ],
                    startTimestamp: 0,
                    endTimestamp: 1.5892063492063493,
                    endReason: "interrupted",
                    ttsTtfb: 0.28243207931518555,
                },
                {
                    role: "user",
                    text: "-",
                    textChunks: [
                        {
                            text: "-",
                            startTimestamp: 1.3892063492063493,
                        },
                    ],
                    startTimestamp: 1.3892063492063493,
                    endTimestamp: 3.2721995464852607,
                    vadBufferMs: 820,
                },
                {
                    role: "assistant",
                    text: "I'm",
                    textChunks: [
                        {
                            text: "I'm",
                            startTimestamp: 0.058049886,
                        },
                    ],
                    startTimestamp: 4.581201814058957,
                    endTimestamp: 5.235691609977324,
                    endReason: "interrupted",
                },
                {
                    role: "user",
                    text: "Hi, Savannah. Nice to meet you.",
                    textChunks: [
                        {
                            text: "Hi, Savannah. Nice to meet you.",
                            startTimestamp: 5.035691609977324,
                        },
                    ],
                    startTimestamp: 5.035691609977324,
                    endTimestamp: 7.058956916099773,
                    vadBufferMs: 464,
                },
                {
                    role: "assistant",
                    text: "It's",
                    textChunks: [
                        {
                            text: "It's",
                            startTimestamp: 0.058049886,
                        },
                    ],
                    startTimestamp: 8.788707482993198,
                    endTimestamp: 11.359954648526077,
                    endReason: "call_ended",
                },
            ],
            telephonyParams: {
                to: "+11234567890",
                from: "+11234567890",
            },
            summary:
                "A brief, fragmented greeting exchange occurs where the human says hello to someone named Savannah.",
            status: "completed",
            deploymentId: "ad_456",
        });
    });

    test("phone-numbers", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                agent_id: "agent_demo",
                number: "+11234567890",
                created_at: "2025-06-06T00:54:01.705Z",
                updated_at: "2025-06-06T01:32:42.879Z",
                is_cartesia_managed: true,
            },
        ];
        server
            .mockEndpoint()
            .get("/agents/agent_demo/phone-numbers")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.phoneNumbers("agent_demo");
        expect(response).toEqual([
            {
                agentId: "agent_demo",
                number: "+11234567890",
                createdAt: new Date("2025-06-06T00:54:01.705Z"),
                updatedAt: new Date("2025-06-06T01:32:42.879Z"),
                isCartesiaManaged: true,
            },
        ]);
    });

    test("list-metrics", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            data: [
                {
                    id: "am_abc123",
                    name: "evaluate-user-satisfaction",
                    display_name: "Evaluate User Satisfaction",
                    prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent’s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) → classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) → classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) → classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
                    created_at: "2025-08-13T16:24:17.457Z",
                },
            ],
            has_more: true,
            next_page: "am_def456",
        };
        server.mockEndpoint().get("/agents/metrics").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.agents.listMetrics();
        expect(response).toEqual({
            data: [
                {
                    id: "am_abc123",
                    name: "evaluate-user-satisfaction",
                    displayName: "Evaluate User Satisfaction",
                    prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent\u2019s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) \u2192 classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) \u2192 classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) \u2192 classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
                    createdAt: new Date("2025-08-13T16:24:17.457Z"),
                },
            ],
            hasMore: true,
            nextPage: "am_def456",
        });
    });

    test("get-metric", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "am_abc123",
            name: "evaluate-user-satisfaction",
            display_name: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent’s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) → classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) → classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) → classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
            created_at: "2025-08-13T16:24:17.457Z",
        };
        server
            .mockEndpoint()
            .get("/agents/metrics/am_abc123")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.getMetric("am_abc123");
        expect(response).toEqual({
            id: "am_abc123",
            name: "evaluate-user-satisfaction",
            displayName: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent\u2019s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) \u2192 classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) \u2192 classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) \u2192 classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
            createdAt: new Date("2025-08-13T16:24:17.457Z"),
        });
    });

    test("create-metric", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });
        const rawRequestBody = {
            name: "evaluate-user-satisfaction",
            display_name: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent’s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) → classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) → classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) → classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
        };
        const rawResponseBody = {
            id: "am_abc123",
            name: "evaluate-user-satisfaction",
            display_name: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent’s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) → classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) → classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) → classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
            created_at: "2025-08-13T16:24:17.457Z",
        };
        server
            .mockEndpoint()
            .post("/agents/metrics")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.createMetric({
            name: "evaluate-user-satisfaction",
            displayName: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent\u2019s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) \u2192 classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) \u2192 classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) \u2192 classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
        });
        expect(response).toEqual({
            id: "am_abc123",
            name: "evaluate-user-satisfaction",
            displayName: "Evaluate User Satisfaction",
            prompt: "Task:\nEvaluate how engaged and satisfied the user is with the conversation. Engagement may be shown through active interest in the agent\u2019s products/services, expressing that the agent was helpful, or indicating they would want to interact again.\n\nDecision Logic:\n- If the user shows strong engagement (asks detailed follow-up questions, expresses high interest, compliments the agent, or states they would use the service/agent again) \u2192 classify as HIGH_SATISFACTION\n- If the user shows some engagement (asks a few relevant questions, shows mild interest, or gives neutral feedback) \u2192 classify as MEDIUM_SATISFACTION\n- If the user shows little or no engagement (short answers, off-topic responses, disinterest, no signs of satisfaction) \u2192 classify as LOW_SATISFACTION\n\nNotes:\n- Engagement can be verbal (explicit statements of interest) or behavioral (asking more about features, prices, benefits, or next steps).\n- Expressions of satisfaction, gratitude, or willingness to call again count as positive engagement.\n- Ignore scripted greetings or polite closings unless they contain genuine feedback.\n\nReturn:\nOnly output the exact category name as a string: HIGH_SATISFACTION, MEDIUM_SATISFACTION, or LOW_SATISFACTION.\n",
            createdAt: new Date("2025-08-13T16:24:17.457Z"),
        });
    });

    test("export-metric-results", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        server.mockEndpoint().get("/agents/metrics/results/export").respondWith().statusCode(200).build();

        const response = await client.agents.exportMetricResults();
        expect(response).toEqual(undefined);
    });

    test("add-metric-to-agent", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        server.mockEndpoint().post("/agents/agent_id/metrics/metric_id").respondWith().statusCode(200).build();

        const response = await client.agents.addMetricToAgent("agent_id", "metric_id");
        expect(response).toEqual(undefined);
    });

    test("remove-metric-from-agent", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        server.mockEndpoint().delete("/agents/agent_id/metrics/metric_id").respondWith().statusCode(200).build();

        const response = await client.agents.removeMetricFromAgent("agent_id", "metric_id");
        expect(response).toEqual(undefined);
    });

    test("list-deployments", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                id: "ad_abc123",
                agent_id: "agent_abc123",
                status: "deployed",
                is_live: true,
                is_pinned: true,
                env_var_collection_id: "env_123",
                source_code_file_id: "scf_456",
                git_commit_hash: "commit_hash_abc",
                created_at: "2025-07-25T06:50:12.889Z",
                updated_at: "2025-07-25T07:00:12.889Z",
                build_completed_at: "2025-07-25T07:10:12.889Z",
                build_error: undefined,
                build_logs: "Build logs here",
                build_started_at: "2025-07-25T06:55:12.889Z",
                deployment_started_at: "2025-07-25T07:15:12.889Z",
                deployment_completed_at: "2025-07-25T07:20:12.889Z",
                deployment_error: undefined,
            },
        ];
        server
            .mockEndpoint()
            .get("/agents/agent_demo/deployments")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.listDeployments("agent_demo");
        expect(response).toEqual([
            {
                id: "ad_abc123",
                agentId: "agent_abc123",
                status: "deployed",
                isLive: true,
                isPinned: true,
                envVarCollectionId: "env_123",
                sourceCodeFileId: "scf_456",
                gitCommitHash: "commit_hash_abc",
                createdAt: new Date("2025-07-25T06:50:12.889Z"),
                updatedAt: new Date("2025-07-25T07:00:12.889Z"),
                buildCompletedAt: new Date("2025-07-25T07:10:12.889Z"),
                buildError: undefined,
                buildLogs: "Build logs here",
                buildStartedAt: new Date("2025-07-25T06:55:12.889Z"),
                deploymentStartedAt: new Date("2025-07-25T07:15:12.889Z"),
                deploymentCompletedAt: new Date("2025-07-25T07:20:12.889Z"),
                deploymentError: undefined,
            },
        ]);
    });

    test("get-deployment", async () => {
        const server = mockServerPool.createServer();
        const client = new CartesiaClient({ token: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "ad_abc123",
            agent_id: "agent_abc123",
            status: "deployed",
            is_live: true,
            is_pinned: true,
            env_var_collection_id: "env_123",
            source_code_file_id: "scf_456",
            git_commit_hash: "commit_hash_abc",
            created_at: "2025-07-25T06:50:12.889Z",
            updated_at: "2025-07-25T07:00:12.889Z",
            build_completed_at: "2025-07-25T07:10:12.889Z",
            build_error: undefined,
            build_logs: "Build logs here",
            build_started_at: "2025-07-25T06:55:12.889Z",
            deployment_started_at: "2025-07-25T07:15:12.889Z",
            deployment_completed_at: "2025-07-25T07:20:12.889Z",
            deployment_error: undefined,
        };
        server
            .mockEndpoint()
            .get("/agents/deployments/ad_abc123")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.getDeployment("ad_abc123");
        expect(response).toEqual({
            id: "ad_abc123",
            agentId: "agent_abc123",
            status: "deployed",
            isLive: true,
            isPinned: true,
            envVarCollectionId: "env_123",
            sourceCodeFileId: "scf_456",
            gitCommitHash: "commit_hash_abc",
            createdAt: new Date("2025-07-25T06:50:12.889Z"),
            updatedAt: new Date("2025-07-25T07:00:12.889Z"),
            buildCompletedAt: new Date("2025-07-25T07:10:12.889Z"),
            buildError: undefined,
            buildLogs: "Build logs here",
            buildStartedAt: new Date("2025-07-25T06:55:12.889Z"),
            deploymentStartedAt: new Date("2025-07-25T07:15:12.889Z"),
            deploymentCompletedAt: new Date("2025-07-25T07:20:12.889Z"),
            deploymentError: undefined,
        });
    });
});
