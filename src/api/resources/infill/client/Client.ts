/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as fs from "fs";
import { Blob } from "buffer";
import * as Cartesia from "../../../index";
import * as stream from "stream";
import * as serializers from "../../../../serialization/index";
import { toJson } from "../../../../core/json";
import urlJoin from "url-join";
import * as errors from "../../../../errors/index";

export declare namespace Infill {
    export interface Options {
        environment?: core.Supplier<environments.CartesiaEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string | undefined>;
        /** Override the Cartesia-Version header */
        cartesiaVersion?: "2024-06-10";
        fetcher?: core.FetchFunction;
    }

    export interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the Cartesia-Version header */
        cartesiaVersion?: "2024-06-10";
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}

export class Infill {
    constructor(protected readonly _options: Infill.Options = {}) {}

    /**
     * Generate audio that smoothly connects two existing audio segments. This is useful for inserting new speech between existing speech segments while maintaining natural transitions.
     *
     * **The cost is 1 credit per character of the infill text plus a fixed cost of 300 credits.**
     *
     * Infilling is only available on `sonic-2` at this time.
     *
     * At least one of `left_audio` or `right_audio` must be provided.
     *
     * As with all generative models, there's some inherent variability, but here's some tips we recommend to get the best results from infill:
     * - Use longer infill transcripts
     *   - This gives the model more flexibility to adapt to the rest of the audio
     * - Target natural pauses in the audio when deciding where to clip
     *   - This means you don't need word-level timestamps to be as precise
     * - Clip right up to the start and end of the audio segment you want infilled, keeping as much silence in the left/right audio segments as possible
     *   - This helps the model generate more natural transitions
     */
    public async bytes(
        leftAudio: File | fs.ReadStream | Blob,
        rightAudio: File | fs.ReadStream | Blob,
        request: Cartesia.InfillBytesRequest,
        requestOptions?: Infill.RequestOptions,
    ): Promise<stream.Readable> {
        const _request = await core.newFormData();
        await _request.appendFile("left_audio", leftAudio);
        await _request.appendFile("right_audio", rightAudio);
        _request.append("model_id", request.modelId);
        _request.append("language", request.language);
        _request.append("transcript", request.transcript);
        _request.append("voice_id", request.voiceId);
        _request.append(
            "output_format[container]",
            serializers.OutputFormatContainer.jsonOrThrow(request.outputFormatContainer, {
                unrecognizedObjectKeys: "strip",
            }),
        );
        _request.append("output_format[sample_rate]", request.outputFormatSampleRate.toString());
        if (request.outputFormatEncoding != null) {
            _request.append(
                "output_format[encoding]",
                serializers.RawEncoding.jsonOrThrow(request.outputFormatEncoding, { unrecognizedObjectKeys: "strip" }),
            );
        }

        if (request.outputFormatBitRate != null) {
            _request.append("output_format[bit_rate]", request.outputFormatBitRate.toString());
        }

        if (request.voiceExperimentalControlsSpeed != null) {
            _request.append(
                "voice[__experimental_controls][speed]",
                (() => {
                    const mapped = serializers.Speed.jsonOrThrow(request.voiceExperimentalControlsSpeed, {
                        unrecognizedObjectKeys: "strip",
                    });
                    return typeof mapped === "string" ? mapped : toJson(mapped);
                })(),
            );
        }

        if (request.voiceExperimentalControlsEmotion != null) {
            for (const _item of request.voiceExperimentalControlsEmotion) {
                _request.append(
                    "voice[__experimental_controls][emotion][]",
                    serializers.Emotion.jsonOrThrow(_item, { unrecognizedObjectKeys: "strip" }),
                );
            }
        }

        const _maybeEncodedRequest = await _request.getRequest();
        const _response = await (this._options.fetcher ?? core.fetcher)<stream.Readable>({
            url: urlJoin(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.CartesiaEnvironment.Production,
                "/infill/bytes",
            ),
            method: "POST",
            headers: {
                "Cartesia-Version": requestOptions?.cartesiaVersion ?? this._options?.cartesiaVersion ?? "2024-06-10",
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "@cartesia/cartesia-js",
                "X-Fern-SDK-Version": "2.2.0",
                "User-Agent": "@cartesia/cartesia-js/2.2.0",
                "X-Fern-Runtime": core.RUNTIME.type,
                "X-Fern-Runtime-Version": core.RUNTIME.version,
                ...(await this._getCustomAuthorizationHeaders()),
                ..._maybeEncodedRequest.headers,
                ...requestOptions?.headers,
            },
            requestType: "file",
            duplex: _maybeEncodedRequest.duplex,
            body: _maybeEncodedRequest.body,
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return _response.body;
        }

        if (_response.error.reason === "status-code") {
            throw new errors.CartesiaError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.CartesiaError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.CartesiaTimeoutError("Timeout exceeded when calling POST /infill/bytes.");
            case "unknown":
                throw new errors.CartesiaError({
                    message: _response.error.errorMessage,
                });
        }
    }

    protected async _getCustomAuthorizationHeaders() {
        const apiKeyValue = await core.Supplier.get(this._options.apiKey);
        return { "X-API-Key": apiKeyValue };
    }
}
