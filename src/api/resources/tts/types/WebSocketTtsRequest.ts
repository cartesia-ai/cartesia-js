/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Cartesia from "../../../index.js";

export interface WebSocketTtsRequest {
    /** The ID of the model to use for the generation. See [Models](/build-with-cartesia/tts-models) for available models. */
    modelId: string;
    outputFormat?: Cartesia.OutputFormat;
    transcript?: string;
    voice: Cartesia.TtsRequestVoiceSpecifier;
    duration?: number;
    language?: string;
    /** Whether to return word-level timestamps. If `false` (default), no word timestamps will be produced at all. If `true`, the server will return timestamp events containing word-level timing information. */
    addTimestamps?: boolean;
    /** Whether to return phoneme-level timestamps. If `false` (default), no phoneme timestamps will be produced. If `true`, the server will return timestamp events containing phoneme-level timing information. */
    addPhonemeTimestamps?: boolean;
    useNormalizedTimestamps?: boolean;
    /** A list of pronunciation dict IDs to use for the generation. This will be applied in addition to the pinned pronunciation dict, which will be treated as the first element of the list. If there are conflicts with dict items, the latest dict will take precedence. */
    pronunciationDictIds?: string[];
    continue?: boolean;
    contextId?: string;
    maxBufferDelayMs?: number;
    speed?: Cartesia.ModelSpeed;
}
